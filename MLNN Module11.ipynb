{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks image recognition - ConvNet\n",
    "\n",
    "1. Add random noise (see below on `size parameter` on [`np.random.normal`](https://numpy.org/doc/stable/reference/random/generated/numpy.random.normal.html)) to the images in training and testing. **Make sure each image gets a different noise feature added to it. Inspect by printing out several images. Note - the `size` parameter should match the data. **\n",
    "2. Compare the `accuracy` of train and val after N epochs for MLNN with and without noise. \n",
    "3. Vary the amount of noise by changing the `scale` parameter in `np.random.normal` by a factor. Use `.1, .5, 1.0, 2.0, 4.0` for the `scale` and keep track of the `accuracy` for training and validation and plot these results.\n",
    "4. Compare these results with the previous week where we used a MultiLayer Perceptron (this week we use a ConvNet). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks - Image Recognition "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conv Net\n",
    "Trains a simple convnet on the MNIST dataset.\n",
    "Gets to 99.25% test accuracy after 12 epochs\n",
    "(there is still a lot of margin for parameter tuning).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "# the data, shuffled and split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "if backend.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "469/469 [==============================] - 84s 176ms/step - loss: 2.2802 - accuracy: 0.1639 - val_loss: 2.2400 - val_accuracy: 0.3622\n",
      "Epoch 2/12\n",
      "469/469 [==============================] - 84s 180ms/step - loss: 2.2157 - accuracy: 0.3035 - val_loss: 2.1615 - val_accuracy: 0.6048\n",
      "Epoch 3/12\n",
      "469/469 [==============================] - 90s 191ms/step - loss: 2.1340 - accuracy: 0.4169 - val_loss: 2.0587 - val_accuracy: 0.6683\n",
      "Epoch 4/12\n",
      "469/469 [==============================] - 89s 190ms/step - loss: 2.0252 - accuracy: 0.4929 - val_loss: 1.9185 - val_accuracy: 0.7101\n",
      "Epoch 5/12\n",
      "469/469 [==============================] - 89s 190ms/step - loss: 1.8813 - accuracy: 0.5465 - val_loss: 1.7339 - val_accuracy: 0.7427\n",
      "Epoch 6/12\n",
      "469/469 [==============================] - 82s 175ms/step - loss: 1.7060 - accuracy: 0.5843 - val_loss: 1.5191 - val_accuracy: 0.7683\n",
      "Epoch 7/12\n",
      "469/469 [==============================] - 86s 183ms/step - loss: 1.5172 - accuracy: 0.6185 - val_loss: 1.3035 - val_accuracy: 0.7906\n",
      "Epoch 8/12\n",
      "469/469 [==============================] - 86s 183ms/step - loss: 1.3517 - accuracy: 0.6453 - val_loss: 1.1153 - val_accuracy: 0.8094\n",
      "Epoch 9/12\n",
      "469/469 [==============================] - 85s 181ms/step - loss: 1.2126 - accuracy: 0.6640 - val_loss: 0.9657 - val_accuracy: 0.8222\n",
      "Epoch 10/12\n",
      "469/469 [==============================] - 74s 158ms/step - loss: 1.0959 - accuracy: 0.6903 - val_loss: 0.8495 - val_accuracy: 0.8338\n",
      "Epoch 11/12\n",
      "469/469 [==============================] - 88s 187ms/step - loss: 1.0135 - accuracy: 0.7067 - val_loss: 0.7627 - val_accuracy: 0.8446\n",
      "Epoch 12/12\n",
      "469/469 [==============================] - 86s 183ms/step - loss: 0.9429 - accuracy: 0.7231 - val_loss: 0.6954 - val_accuracy: 0.8522\n",
      "Test loss: 0.6953843832015991\n",
      "Test accuracy: 0.8521999716758728\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 12\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "# the data, shuffled and split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "if backend.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "noisetrain = np.random.normal(loc = 0, scale = .1, size = [60000, 28, 28, 1])\n",
    "noisetest = np.random.normal(loc = 0,scale = .1,size = [10000, 28, 28, 1])\n",
    "noisy_train = noisetrain + x_train\n",
    "noisy_test = noisetest + x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "469/469 [==============================] - 74s 156ms/step - loss: 2.2783 - accuracy: 0.1420 - val_loss: 2.2376 - val_accuracy: 0.2540\n",
      "Epoch 2/12\n",
      "469/469 [==============================] - 78s 166ms/step - loss: 2.2149 - accuracy: 0.2513 - val_loss: 2.1569 - val_accuracy: 0.5037\n",
      "Epoch 3/12\n",
      "469/469 [==============================] - 81s 174ms/step - loss: 2.1307 - accuracy: 0.3645 - val_loss: 2.0475 - val_accuracy: 0.6368\n",
      "Epoch 4/12\n",
      "469/469 [==============================] - 74s 158ms/step - loss: 2.0188 - accuracy: 0.4559 - val_loss: 1.9010 - val_accuracy: 0.7135\n",
      "Epoch 5/12\n",
      "469/469 [==============================] - 86s 184ms/step - loss: 1.8721 - accuracy: 0.5243 - val_loss: 1.7158 - val_accuracy: 0.7487\n",
      "Epoch 6/12\n",
      "469/469 [==============================] - 77s 165ms/step - loss: 1.6997 - accuracy: 0.5747 - val_loss: 1.5065 - val_accuracy: 0.7765\n",
      "Epoch 7/12\n",
      "469/469 [==============================] - 78s 165ms/step - loss: 1.5190 - accuracy: 0.6084 - val_loss: 1.2978 - val_accuracy: 0.7944\n",
      "Epoch 8/12\n",
      "469/469 [==============================] - 83s 176ms/step - loss: 1.3544 - accuracy: 0.6375 - val_loss: 1.1144 - val_accuracy: 0.8097\n",
      "Epoch 9/12\n",
      "469/469 [==============================] - 81s 172ms/step - loss: 1.2106 - accuracy: 0.6657 - val_loss: 0.9674 - val_accuracy: 0.8231\n",
      "Epoch 10/12\n",
      "469/469 [==============================] - 76s 162ms/step - loss: 1.1008 - accuracy: 0.6890 - val_loss: 0.8538 - val_accuracy: 0.8298\n",
      "Epoch 11/12\n",
      "469/469 [==============================] - 85s 181ms/step - loss: 1.0088 - accuracy: 0.7070 - val_loss: 0.7658 - val_accuracy: 0.8380\n",
      "Epoch 12/12\n",
      "469/469 [==============================] - 76s 163ms/step - loss: 0.9404 - accuracy: 0.7232 - val_loss: 0.6990 - val_accuracy: 0.8464\n",
      "Test loss: 0.6990057826042175\n",
      "Test accuracy: 0.8464000225067139\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 12\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size = (3, 3),\n",
    "                 activation = 'relu',\n",
    "                 input_shape = input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation = 'relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation = 'softmax'))\n",
    "\n",
    "model.compile(loss = keras.losses.categorical_crossentropy,\n",
    "              optimizer = keras.optimizers.Adadelta(),\n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "model.fit(noisy_train, y_train,\n",
    "          batch_size = batch_size,\n",
    "          epochs = epochs,\n",
    "          verbose = 1,\n",
    "          validation_data = (noisy_test, y_test))\n",
    "score = model.evaluate(noisy_test, y_test, verbose = 0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "score5 = score[1]\n",
    "\n",
    "#Not as accurate as no noise but still accurate enough and more accurate than the Multilayer Perception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "# the data, shuffled and split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "if backend.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "noisetrain1 = np.random.normal(loc = 0, scale = .5, size = [60000, 28, 28, 1])\n",
    "noisetest1 = np.random.normal(loc = 0,scale = .5,size = [10000, 28, 28, 1])\n",
    "noisy_train1 = noisetrain1 + x_train\n",
    "noisy_test1 = noisetest1 + x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "469/469 [==============================] - 76s 159ms/step - loss: 2.3000 - accuracy: 0.1133 - val_loss: 2.2641 - val_accuracy: 0.2462\n",
      "Epoch 2/12\n",
      "469/469 [==============================] - 75s 160ms/step - loss: 2.2649 - accuracy: 0.1625 - val_loss: 2.2270 - val_accuracy: 0.3976\n",
      "Epoch 3/12\n",
      "469/469 [==============================] - 74s 158ms/step - loss: 2.2316 - accuracy: 0.2038 - val_loss: 2.1862 - val_accuracy: 0.4805\n",
      "Epoch 4/12\n",
      "469/469 [==============================] - 74s 158ms/step - loss: 2.1944 - accuracy: 0.2423 - val_loss: 2.1377 - val_accuracy: 0.5468\n",
      "Epoch 5/12\n",
      "469/469 [==============================] - 74s 157ms/step - loss: 2.1495 - accuracy: 0.2812 - val_loss: 2.0784 - val_accuracy: 0.5990\n",
      "Epoch 6/12\n",
      "469/469 [==============================] - 71s 152ms/step - loss: 2.0945 - accuracy: 0.3227 - val_loss: 2.0066 - val_accuracy: 0.6463\n",
      "Epoch 7/12\n",
      "469/469 [==============================] - 73s 155ms/step - loss: 2.0292 - accuracy: 0.3647 - val_loss: 1.9221 - val_accuracy: 0.6761\n",
      "Epoch 8/12\n",
      "469/469 [==============================] - 72s 154ms/step - loss: 1.9509 - accuracy: 0.4091 - val_loss: 1.8254 - val_accuracy: 0.6978\n",
      "Epoch 9/12\n",
      "469/469 [==============================] - 73s 156ms/step - loss: 1.8644 - accuracy: 0.4514 - val_loss: 1.7189 - val_accuracy: 0.7113\n",
      "Epoch 10/12\n",
      "469/469 [==============================] - 70s 149ms/step - loss: 1.7718 - accuracy: 0.4847 - val_loss: 1.6059 - val_accuracy: 0.7238\n",
      "Epoch 11/12\n",
      "469/469 [==============================] - 70s 149ms/step - loss: 1.6723 - accuracy: 0.5219 - val_loss: 1.4908 - val_accuracy: 0.7362\n",
      "Epoch 12/12\n",
      "469/469 [==============================] - 72s 155ms/step - loss: 1.5779 - accuracy: 0.5475 - val_loss: 1.3792 - val_accuracy: 0.7435\n",
      "Test loss: 1.379181981086731\n",
      "Test accuracy: 0.7434999942779541\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 12\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size = (3, 3),\n",
    "                 activation = 'relu',\n",
    "                 input_shape = input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation = 'relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation = 'softmax'))\n",
    "\n",
    "model.compile(loss = keras.losses.categorical_crossentropy,\n",
    "              optimizer = keras.optimizers.Adadelta(),\n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "model.fit(noisy_train1, y_train,\n",
    "          batch_size = batch_size,\n",
    "          epochs = epochs,\n",
    "          verbose = 1,\n",
    "          validation_data = (noisy_test1, y_test))\n",
    "score = model.evaluate(noisy_test1, y_test, verbose = 0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "score1 = score[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "# the data, shuffled and split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "if backend.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "noisetrain2 = np.random.normal(loc = 0, scale = 1, size = [60000, 28, 28, 1])\n",
    "noisetest2 = np.random.normal(loc = 0,scale = 1,size = [10000, 28, 28, 1])\n",
    "noisy_train2 = noisetrain2 + x_train\n",
    "noisy_test2 = noisetest2 + x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "469/469 [==============================] - 74s 156ms/step - loss: 2.3396 - accuracy: 0.0997 - val_loss: 2.2966 - val_accuracy: 0.1188\n",
      "Epoch 2/12\n",
      "469/469 [==============================] - 72s 153ms/step - loss: 2.3078 - accuracy: 0.1162 - val_loss: 2.2805 - val_accuracy: 0.1648\n",
      "Epoch 3/12\n",
      "469/469 [==============================] - 68s 145ms/step - loss: 2.2918 - accuracy: 0.1285 - val_loss: 2.2678 - val_accuracy: 0.2073\n",
      "Epoch 4/12\n",
      "469/469 [==============================] - 74s 157ms/step - loss: 2.2803 - accuracy: 0.1424 - val_loss: 2.2544 - val_accuracy: 0.2424\n",
      "Epoch 5/12\n",
      "469/469 [==============================] - 80s 172ms/step - loss: 2.2680 - accuracy: 0.1531 - val_loss: 2.2390 - val_accuracy: 0.2817\n",
      "Epoch 6/12\n",
      "469/469 [==============================] - 82s 175ms/step - loss: 2.2536 - accuracy: 0.1702 - val_loss: 2.2192 - val_accuracy: 0.3256\n",
      "Epoch 7/12\n",
      "469/469 [==============================] - 84s 178ms/step - loss: 2.2378 - accuracy: 0.1853 - val_loss: 2.1962 - val_accuracy: 0.3614\n",
      "Epoch 8/12\n",
      "469/469 [==============================] - 87s 185ms/step - loss: 2.2210 - accuracy: 0.2001 - val_loss: 2.1701 - val_accuracy: 0.3997\n",
      "Epoch 9/12\n",
      "469/469 [==============================] - 84s 179ms/step - loss: 2.1975 - accuracy: 0.2206 - val_loss: 2.1403 - val_accuracy: 0.4217\n",
      "Epoch 10/12\n",
      "469/469 [==============================] - 84s 179ms/step - loss: 2.1727 - accuracy: 0.2371 - val_loss: 2.1055 - val_accuracy: 0.4496\n",
      "Epoch 11/12\n",
      "469/469 [==============================] - 87s 185ms/step - loss: 2.1428 - accuracy: 0.2526 - val_loss: 2.0658 - val_accuracy: 0.4784\n",
      "Epoch 12/12\n",
      "469/469 [==============================] - 83s 177ms/step - loss: 2.1083 - accuracy: 0.2785 - val_loss: 2.0225 - val_accuracy: 0.4989\n",
      "Test loss: 2.022512197494507\n",
      "Test accuracy: 0.49889999628067017\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 12\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size = (3, 3),\n",
    "                 activation = 'relu',\n",
    "                 input_shape = input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation = 'relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation = 'softmax'))\n",
    "\n",
    "model.compile(loss = keras.losses.categorical_crossentropy,\n",
    "              optimizer = keras.optimizers.Adadelta(),\n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "model.fit(noisy_train2, y_train,\n",
    "          batch_size = batch_size,\n",
    "          epochs = epochs,\n",
    "          verbose = 1,\n",
    "          validation_data = (noisy_test2, y_test))\n",
    "score = model.evaluate(noisy_test2, y_test, verbose = 0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "score2 = score[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "# the data, shuffled and split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "if backend.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "noisetrain3 = np.random.normal(loc = 0, scale = 2, size = [60000, 28, 28, 1])\n",
    "noisetest3 = np.random.normal(loc = 0,scale = 2,size = [10000, 28, 28, 1])\n",
    "noisy_train3 = noisetrain3 + x_train\n",
    "noisy_test3 = noisetest3 + x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "469/469 [==============================] - 74s 155ms/step - loss: 2.4264 - accuracy: 0.1033 - val_loss: 2.3098 - val_accuracy: 0.1086\n",
      "Epoch 2/12\n",
      "469/469 [==============================] - 78s 165ms/step - loss: 2.3413 - accuracy: 0.1034 - val_loss: 2.3001 - val_accuracy: 0.1141\n",
      "Epoch 3/12\n",
      "469/469 [==============================] - 75s 159ms/step - loss: 2.3170 - accuracy: 0.1068 - val_loss: 2.2975 - val_accuracy: 0.1188\n",
      "Epoch 4/12\n",
      "469/469 [==============================] - 86s 184ms/step - loss: 2.3072 - accuracy: 0.1112 - val_loss: 2.2966 - val_accuracy: 0.1307\n",
      "Epoch 5/12\n",
      "469/469 [==============================] - 79s 167ms/step - loss: 2.3031 - accuracy: 0.1131 - val_loss: 2.2963 - val_accuracy: 0.1366\n",
      "Epoch 6/12\n",
      "469/469 [==============================] - 67s 143ms/step - loss: 2.3008 - accuracy: 0.1158 - val_loss: 2.2956 - val_accuracy: 0.1378\n",
      "Epoch 7/12\n",
      "469/469 [==============================] - 73s 156ms/step - loss: 2.2987 - accuracy: 0.1199 - val_loss: 2.2948 - val_accuracy: 0.1410\n",
      "Epoch 8/12\n",
      "469/469 [==============================] - 71s 152ms/step - loss: 2.2975 - accuracy: 0.1199 - val_loss: 2.2935 - val_accuracy: 0.1453\n",
      "Epoch 9/12\n",
      "469/469 [==============================] - 68s 146ms/step - loss: 2.2966 - accuracy: 0.1209 - val_loss: 2.2914 - val_accuracy: 0.1492\n",
      "Epoch 10/12\n",
      "469/469 [==============================] - 69s 147ms/step - loss: 2.2938 - accuracy: 0.1271 - val_loss: 2.2883 - val_accuracy: 0.1546\n",
      "Epoch 11/12\n",
      "469/469 [==============================] - 71s 152ms/step - loss: 2.2924 - accuracy: 0.1261 - val_loss: 2.2852 - val_accuracy: 0.1569\n",
      "Epoch 12/12\n",
      "469/469 [==============================] - 69s 147ms/step - loss: 2.2892 - accuracy: 0.1297 - val_loss: 2.2807 - val_accuracy: 0.1679\n",
      "Test loss: 2.2806756496429443\n",
      "Test accuracy: 0.1678999960422516\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 12\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size = (3, 3),\n",
    "                 activation = 'relu',\n",
    "                 input_shape = input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation = 'relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation = 'softmax'))\n",
    "\n",
    "model.compile(loss = keras.losses.categorical_crossentropy,\n",
    "              optimizer = keras.optimizers.Adadelta(),\n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "model.fit(noisy_train3, y_train,\n",
    "          batch_size = batch_size,\n",
    "          epochs = epochs,\n",
    "          verbose = 1,\n",
    "          validation_data = (noisy_test3, y_test))\n",
    "score = model.evaluate(noisy_test3, y_test, verbose = 0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "score3 = score[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "# the data, shuffled and split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "if backend.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "noisetrain4 = np.random.normal(loc = 0, scale = 4, size = [60000, 28, 28, 1])\n",
    "noisetest4 = np.random.normal(loc = 0, scale = 4,size = [10000, 28, 28, 1])\n",
    "noisy_train4 = noisetrain4 + x_train\n",
    "noisy_test4 = noisetest4 + x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "469/469 [==============================] - 69s 146ms/step - loss: 2.5833 - accuracy: 0.1003 - val_loss: 2.3177 - val_accuracy: 0.1011\n",
      "Epoch 2/12\n",
      "469/469 [==============================] - 70s 149ms/step - loss: 2.3734 - accuracy: 0.1024 - val_loss: 2.3045 - val_accuracy: 0.1065\n",
      "Epoch 3/12\n",
      "469/469 [==============================] - 74s 158ms/step - loss: 2.3265 - accuracy: 0.1013 - val_loss: 2.3027 - val_accuracy: 0.1041\n",
      "Epoch 4/12\n",
      "469/469 [==============================] - 75s 159ms/step - loss: 2.3143 - accuracy: 0.1024 - val_loss: 2.3025 - val_accuracy: 0.1036\n",
      "Epoch 5/12\n",
      "469/469 [==============================] - 82s 175ms/step - loss: 2.3080 - accuracy: 0.0998 - val_loss: 2.3024 - val_accuracy: 0.1107\n",
      "Epoch 6/12\n",
      "469/469 [==============================] - 76s 161ms/step - loss: 2.3071 - accuracy: 0.1035 - val_loss: 2.3024 - val_accuracy: 0.1119\n",
      "Epoch 7/12\n",
      "469/469 [==============================] - 78s 167ms/step - loss: 2.3059 - accuracy: 0.1066 - val_loss: 2.3023 - val_accuracy: 0.1146\n",
      "Epoch 8/12\n",
      "469/469 [==============================] - 66s 140ms/step - loss: 2.3048 - accuracy: 0.1057 - val_loss: 2.3024 - val_accuracy: 0.1135\n",
      "Epoch 9/12\n",
      "469/469 [==============================] - 80s 170ms/step - loss: 2.3048 - accuracy: 0.1055 - val_loss: 2.3025 - val_accuracy: 0.1130\n",
      "Epoch 10/12\n",
      "469/469 [==============================] - 62s 132ms/step - loss: 2.3039 - accuracy: 0.1059 - val_loss: 2.3025 - val_accuracy: 0.1127\n",
      "Epoch 11/12\n",
      "469/469 [==============================] - 76s 162ms/step - loss: 2.3041 - accuracy: 0.1076 - val_loss: 2.3024 - val_accuracy: 0.1147\n",
      "Epoch 12/12\n",
      "469/469 [==============================] - 75s 160ms/step - loss: 2.3040 - accuracy: 0.1049 - val_loss: 2.3025 - val_accuracy: 0.1133\n",
      "Test loss: 2.3024559020996094\n",
      "Test accuracy: 0.11330000311136246\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 12\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size = (3, 3),\n",
    "                 activation = 'relu',\n",
    "                 input_shape = input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation = 'relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation = 'softmax'))\n",
    "\n",
    "model.compile(loss = keras.losses.categorical_crossentropy,\n",
    "              optimizer = keras.optimizers.Adadelta(),\n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "model.fit(noisy_train4, y_train,\n",
    "          batch_size = batch_size,\n",
    "          epochs = epochs,\n",
    "          verbose = 1,\n",
    "          validation_data = (noisy_test4, y_test))\n",
    "score = model.evaluate(noisy_test4, y_test, verbose = 0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "score4 = score[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_scores = [score5, score1, score2, score3, score4]\n",
    "all_scores\n",
    "all_scales = [0.1, 0.5, 1, 2 ,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(all_scales, all_scores)\n",
    "plt.xlabel('Scale')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Last week we saw that accuracy didn't only decrease with the scale. We saw a massive increase at scale 1. We are noticing\n",
    "# this week with Convnet that as scale increases, accuracy decreases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
